{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "47ee6299d7d5477ba08a1db503659dd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87be78716bc34d138e6ecaf5b98d3b95",
              "IPY_MODEL_ea3ac56303084563b757dcfcffb9be9a",
              "IPY_MODEL_dcfdd57f4e0a4913b7ab13149f83fcdd"
            ],
            "layout": "IPY_MODEL_c11ada73f3bf47c29d2d5dfc25ec1a7b"
          }
        },
        "87be78716bc34d138e6ecaf5b98d3b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e486e12c834457a830f8fa5ddea132f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a5a22bd1410d4435a7a8dad84719d24e",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "ea3ac56303084563b757dcfcffb9be9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7d90a98894a48ed9e186382716d625d",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22e37776948b4657887f9e7c36a32d4d",
            "value": 8
          }
        },
        "dcfdd57f4e0a4913b7ab13149f83fcdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e315e7df4a5488cb329c4ec6aecbcd9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f5ba53487a3f4c328e49d91011ea818f",
            "value": "‚Äá8/8‚Äá[00:04&lt;00:00,‚Äá‚Äá1.96it/s]"
          }
        },
        "c11ada73f3bf47c29d2d5dfc25ec1a7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e486e12c834457a830f8fa5ddea132f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5a22bd1410d4435a7a8dad84719d24e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7d90a98894a48ed9e186382716d625d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22e37776948b4657887f9e7c36a32d4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e315e7df4a5488cb329c4ec6aecbcd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5ba53487a3f4c328e49d91011ea818f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3thcHVIKzLio",
        "outputId": "33f0d5b1-dfea-4ee6-bdbf-80962854c278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   145  100   145    0     0    267      0 --:--:-- --:--:-- --:--:--   267\n",
            "100 1042M  100 1042M    0     0  26.4M      0  0:00:39  0:00:39 --:--:-- 30.9M\n"
          ]
        }
      ],
      "source": [
        "!curl -L -o data.csv.gz \"https://static.openfoodfacts.org/data/en.openfoodfacts.org.products.csv.gz\"\n",
        "!gunzip 'data.csv.gz'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1cjR3vKZkwt_pzIy3oBWTCHczBnywF06l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBMU6Akv55Uc",
        "outputId": "83127579-c806-4542-b1b5-7d814a45a734"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cjR3vKZkwt_pzIy3oBWTCHczBnywF06l\n",
            "To: /content/unhealthy_ingredients.json\n",
            "\r  0% 0.00/9.14k [00:00<?, ?B/s]\r100% 9.14k/9.14k [00:00<00:00, 27.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers accelerate sentencepiece bitsandbytes gradio accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5LyBGkN0F96",
        "outputId": "6dee6506-c739-4335-c565-4dc6f8b840c0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.29.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.10.0 (from gradio)\n",
            "  Downloading gradio_client-1.10.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.29.0-py3-none-any.whl (54.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m126.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.29.0 gradio-client-1.10.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.8 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import sys\n",
        "import json\n",
        "import gradio as gr\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "# ----------- CONFIGURATION ----------- #\n",
        "DATA_PATH = \"data.csv\"\n",
        "UNHEALTHY_INGREDIENT_PATH = \"/content/unhealthy_ingredients.json\"\n",
        "MODEL_NAME = \"HuggingFaceH4/zephyr-7b-beta\"\n",
        "MAX_NEW_TOKENS = 256\n",
        "\n",
        "# ----------- MODEL LOADING ----------- #\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=\"auto\", torch_dtype=\"auto\")\n",
        "chatbot = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=MAX_NEW_TOKENS,\n",
        "                   do_sample=False, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "# ----------- LOAD METADATA ----------- #\n",
        "def load_metadata(path, chunksize=100000, max_chunks=3):\n",
        "    sample = pd.read_csv(path, sep=\"\\t\", nrows=5, dtype=str, encoding='utf-8', on_bad_lines='skip')\n",
        "    sample.columns = sample.columns.str.strip().str.lower()\n",
        "    product_col = next((col for col in sample.columns if \"product\" in col and \"name\" in col), None)\n",
        "    brand_col = next((col for col in sample.columns if \"brand\" in col), None)\n",
        "\n",
        "    metadata = []\n",
        "    for i, chunk in enumerate(pd.read_csv(path, sep=\"\\t\", chunksize=chunksize, dtype=str, encoding='utf-8', on_bad_lines='skip')):\n",
        "        for idx, row in chunk.iterrows():\n",
        "            metadata.append({\n",
        "                \"line\": i * chunksize + idx + 1,\n",
        "                \"product_name\": row.get(product_col, \"\"),\n",
        "                \"brands\": row.get(brand_col, \"\")\n",
        "            })\n",
        "        if i + 1 >= max_chunks:\n",
        "            break\n",
        "    return pd.DataFrame(metadata)\n",
        "\n",
        "PRODUCT_METADATA = load_metadata(DATA_PATH)\n",
        "\n",
        "def read_row_by_index(csv_path, index):\n",
        "    csv.field_size_limit(sys.maxsize)\n",
        "    with open(csv_path, encoding=\"utf-8\") as f:\n",
        "        reader = csv.reader(f, delimiter=\"\\t\")\n",
        "        header = next(reader)\n",
        "        for i, row in enumerate(reader, start=1):\n",
        "            if i == index:\n",
        "                return {k.strip().lower(): v for k, v in zip(header, row)}\n",
        "    return {}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "47ee6299d7d5477ba08a1db503659dd6",
            "87be78716bc34d138e6ecaf5b98d3b95",
            "ea3ac56303084563b757dcfcffb9be9a",
            "dcfdd57f4e0a4913b7ab13149f83fcdd",
            "c11ada73f3bf47c29d2d5dfc25ec1a7b",
            "8e486e12c834457a830f8fa5ddea132f",
            "a5a22bd1410d4435a7a8dad84719d24e",
            "b7d90a98894a48ed9e186382716d625d",
            "22e37776948b4657887f9e7c36a32d4d",
            "2e315e7df4a5488cb329c4ec6aecbcd9",
            "f5ba53487a3f4c328e49d91011ea818f"
          ]
        },
        "id": "hCUZuYe0Suyb",
        "outputId": "8fe73d8d-3d84-4f3d-d70a-03d6748d5f77"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47ee6299d7d5477ba08a1db503659dd6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------- HEALTH ANALYSIS ----------- #\n",
        "with open(UNHEALTHY_INGREDIENT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    UNHEALTHY_INGREDIENT_DATA = json.load(f)\n",
        "\n",
        "UNHEALTHY_LOOKUP = {\n",
        "    alias.lower(): (entry[\"ingredient\"], entry[\"reason\"])\n",
        "    for entry in UNHEALTHY_INGREDIENT_DATA\n",
        "    for alias in [entry[\"ingredient\"]] + entry.get(\"aliases\", [])\n",
        "}\n",
        "\n",
        "def assess_ingredient_healthiness(ingredients_text):\n",
        "    ingredients = ingredients_text.lower()\n",
        "    found = []\n",
        "    for alias, (canonical, reason) in UNHEALTHY_LOOKUP.items():\n",
        "        if alias in ingredients:\n",
        "            found.append(f\"{canonical} ‚Üí {reason}\")\n",
        "    ingredients_list = [i.strip() for i in ingredients.split(\",\")][:5]\n",
        "    if any(\"sugar\" in item for item in ingredients_list):\n",
        "        found.append(\"Sugar is one of the first ingredients\")\n",
        "    return \"No obvious unhealthy ingredients found.\" if not found else \"This product may be unhealthy due to:\\n- \" + \"\\n- \".join(found)\n",
        "\n",
        "# ----------- ALLERGEN CHECK ----------- #\n",
        "KNOWN_ALLERGENS = [\n",
        "    \"milk\", \"soy\", \"nuts\", \"peanuts\", \"almond\", \"cashew\", \"hazelnut\", \"walnut\", \"egg\",\n",
        "    \"wheat\", \"gluten\", \"shellfish\", \"fish\", \"sesame\", \"mustard\", \"lupin\", \"celery\", \"sulfite\"\n",
        "]\n",
        "\n",
        "def check_allergen_presence(ingredients_text):\n",
        "    ingredients = ingredients_text.lower()\n",
        "    found = [a for a in KNOWN_ALLERGENS if a in ingredients]\n",
        "    return \"No common allergens detected.\" if not found else \"May contain: \" + \", \".join(sorted(set(found)))\n",
        "\n",
        "# ----------- NUTRITION CONTEXT ----------- #\n",
        "def get_full_context(product):\n",
        "    ingredients = product.get(\"ingredients_text\", \"\")\n",
        "    product[\"allergen_analysis\"] = check_allergen_presence(ingredients)\n",
        "    product[\"health\"] = assess_ingredient_healthiness(ingredients)\n",
        "    return product\n",
        "\n",
        "# ----------- PROMPT BUILDING ----------- #\n",
        "def build_prompt(product, health, user_input):\n",
        "    return f\"\"\"### Instruction:\n",
        "Answer concisely using the facts provided.\n",
        "\n",
        "### Product:\n",
        "Name: {product.get(\"product_name\")}\n",
        "Brand: {product.get(\"brands\")}\n",
        "Energy: {product.get(\"energy-kcal_100g\")} kcal\n",
        "Fat: {product.get(\"fat_100g\")}g | Sat Fat: {product.get(\"saturated-fat_100g\")}g\n",
        "Sugars: {product.get(\"sugars_100g\")}g | Fiber: {product.get(\"fiber_100g\")}g\n",
        "Protein: {product.get(\"proteins_100g\")}g | Salt: {product.get(\"salt_100g\")}g\n",
        "Ingredients: {product.get(\"ingredients_text\")[:300]}...\n",
        "Allergens (label): {product.get(\"allergens\")}\n",
        "Allergen Check: {product.get(\"allergen_analysis\")}\n",
        "Labels: {product.get(\"labels_tags\")}\n",
        "Health Insight: {health}\n",
        "\n",
        "### Question:\n",
        "{user_input}\n",
        "\n",
        "### Answer:\"\"\"\n",
        "\n",
        "# ----------- GRADIO LOGIC ----------- #\n",
        "def get_matching_products(product_name):\n",
        "    matches = PRODUCT_METADATA[\n",
        "        PRODUCT_METADATA[\"product_name\"].str.lower().str.contains(product_name.lower(), na=False)\n",
        "    ]\n",
        "    if matches.empty:\n",
        "        return [], \"‚ùå No matching products found.\"\n",
        "    options = [f\"{row['product_name']} (line {row['line']})\" for _, row in matches.iterrows()]\n",
        "    return options, \"‚úÖ Select a product from the dropdown.\"\n",
        "\n",
        "def answer_question(selected_product_label, question):\n",
        "    if not selected_product_label or \"line\" not in selected_product_label:\n",
        "        return \"‚ùå Please select a valid product.\"\n",
        "    try:\n",
        "        line = int(selected_product_label.split(\"line\")[-1].strip(\" )\"))\n",
        "        product_row = read_row_by_index(DATA_PATH, line)\n",
        "        if not product_row:\n",
        "            return \"‚ùå Could not load product details.\"\n",
        "        context = get_full_context(product_row)\n",
        "        prompt = build_prompt(context, context[\"health\"], question)\n",
        "        input_ids = tokenizer(prompt)[\"input_ids\"]\n",
        "        if len(input_ids) > 3000:\n",
        "            prompt = tokenizer.decode(input_ids[-3000:], skip_special_tokens=True)\n",
        "        result = chatbot(prompt)\n",
        "        output = result[0][\"generated_text\"]\n",
        "        answer = output[len(prompt):].split(\"User:\")[0].strip()\n",
        "        return answer or \"‚ö†Ô∏è No answer generated.\"\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error: {e}\"\n",
        "\n",
        "# ----------- GRADIO UI ----------- #\n",
        "with gr.Blocks(title=\"Nutrition Chatbot\") as demo:\n",
        "    gr.Markdown(\"## üç´ Nutrition Chatbot\\nSearch and analyze food products from Open Food Facts.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        product_input = gr.Textbox(label=\"Enter product name\", placeholder=\"e.g. chocolate bar\")\n",
        "        search_button = gr.Button(\"üîç Search\")\n",
        "\n",
        "    product_dropdown = gr.Dropdown(choices=[], label=\"Matching Products\", interactive=True)\n",
        "\n",
        "    with gr.Row():\n",
        "        question_box = gr.Textbox(label=\"Ask a Question\", placeholder=\"e.g. Is this product high in sugar?\")\n",
        "        ask_button = gr.Button(\"üí¨ Ask\")\n",
        "\n",
        "    answer_box = gr.Textbox(label=\"Response\", lines=5)\n",
        "\n",
        "    def handle_search(product_name):\n",
        "        options, status = get_matching_products(product_name)\n",
        "        return gr.update(choices=options, value=None), status\n",
        "\n",
        "    search_button.click(fn=handle_search, inputs=product_input, outputs=[product_dropdown, answer_box])\n",
        "    ask_button.click(fn=answer_question, inputs=[product_dropdown, question_box], outputs=answer_box)\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "kO3j1DWYXm2G",
        "outputId": "dff180e0-9871-4d6a-85e0-b106cf0607da"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3ce4b05fbdbd35e8d3.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3ce4b05fbdbd35e8d3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "def answer_question(selected_product_label, question):\n",
        "    if not selected_product_label or \"line\" not in selected_product_label:\n",
        "        return \"‚ùå Please select a valid product.\"\n",
        "\n",
        "    try:\n",
        "        line = int(selected_product_label.split(\"line\")[-1].strip(\" )\"))\n",
        "        product_row = read_row_by_index(DATA_PATH, line)\n",
        "        if not product_row:\n",
        "            return \"‚ùå Could not load product details.\"\n",
        "\n",
        "        context = get_full_context(product_row)\n",
        "        prompt = build_prompt(context, context[\"health\"], question)\n",
        "\n",
        "        input_ids = tokenizer(prompt)[\"input_ids\"]\n",
        "        if len(input_ids) > 3000:\n",
        "            prompt = tokenizer.decode(input_ids[-3000:], skip_special_tokens=True)\n",
        "\n",
        "        print(f\"\\nüß† Prompt Tokens: {len(input_ids)}\")\n",
        "\n",
        "        # Start timer\n",
        "        start_time = time.time()\n",
        "        result = chatbot(prompt)\n",
        "        end_time = time.time()\n",
        "\n",
        "        output = result[0][\"generated_text\"]\n",
        "        response_tokens = tokenizer(output[len(prompt):])[\"input_ids\"]\n",
        "        duration = end_time - start_time\n",
        "\n",
        "        # Print metrics\n",
        "        print(f\"‚úÖ Response Tokens: {len(response_tokens)}\")\n",
        "        print(f\"‚è±Ô∏è Inference Time: {duration:.2f} seconds\")\n",
        "        print(f\"üñ•Ô∏è CUDA Memory Allocated: {torch.cuda.memory_allocated() / 1e6:.1f} MB\")\n",
        "        print(f\"üñ•Ô∏è CUDA Max Memory Used: {torch.cuda.max_memory_allocated() / 1e6:.1f} MB\")\n",
        "\n",
        "        return output[len(prompt):].split(\"User:\")[0].strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error: {e}\"\n",
        "\n",
        "question = \"Is this product high in sugar?\"\n",
        "selected_product_label = \"Milk Chocolate (line 1234)\"  # üîÅ Replace with a real product line from dropdown\n",
        "\n",
        "print(answer_question(selected_product_label, question))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8OO29-UZOE6",
        "outputId": "855f9786-f122-4b59-9927-f30717c95b4d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß† Prompt Tokens: 128\n",
            "‚úÖ Response Tokens: 102\n",
            "‚è±Ô∏è Inference Time: 4.21 seconds\n",
            "üñ•Ô∏è CUDA Memory Allocated: 14517.5 MB\n",
            "üñ•Ô∏è CUDA Max Memory Used: 28966.9 MB\n",
            "Based on the provided information, it is unclear whether this product is high in sugar as the amount of sugars is not specified as high or low. However, the amount of sugars is listed as grams (g), and the value provided is....g. It is up to personal preference and dietary needs to determine if this amount of sugar is considered high or not. Without further context or information, it is best to assume that the product is not excessively high in sugar.\n"
          ]
        }
      ]
    }
  ]
}